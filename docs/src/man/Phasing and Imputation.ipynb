{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Target Data\n",
    "\n",
    "MendelImpute accepts [VCF](https://samtools.github.io/hts-specs/VCFv4.3.pdf) and [PLINK](https://www.cog-genomics.org/plink2/formats#bed) files. Please make sure the following are true:\n",
    "\n",
    "+ VCF file ends in `.vcf` or `.vcf.gz` (phased or unphased and may contain missing data)\n",
    "+ For PLINK files, all trios (`.bim`, `.bed`, `.fam`) are present in the same directory\n",
    "+ Each file contains only 1 (non-sex) chromosome\n",
    "+ Every record (SNP) is present in the reference panel. If this is untrue, you must [match markers in 2 VCF files](https://openmendel.github.io/VCFTools.jl/dev/man/conformgt/). \n",
    "+ Given a SNP, it's CHROM, POS, REF, and  ALT fields are the same in target data and reference panel. MendelImpute use SNP position internally to align markers. Note this is not explicitly checked. \n",
    "+ The position of every SNP is unique: so multiallelic markers should be excluded instead of split (this requirement will eventually be lifted). \n",
    "\n",
    "The following are not necessary but recommended for pre-imputation quality control:\n",
    "\n",
    "+ Exclude markers with Hardy-Weinberg p-values $< 10^{-5}$. \n",
    "+ Exclude markers with minor allele frequency $< 10^{-6}$\n",
    "+ Exclude samples with $>3\\%$ missing genotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Reference Haplotype Panel\n",
    "\n",
    "Reference samples must all be phased and contain no missing genotypes. Reference VCF panels must be compressed into `.jlso` format first using the [compress_haplotypes](https://OpenMendel.github.io/MendelImpute.jl/dev/man/api/#MendelImpute.compress_haplotypes) function. One must specify `d`: the maximum number of unique haplotypes per window. Larger `d` slows down computation, but increases accuracy. For most purposes, we recommend $d \\approx 1000$. A larger `d` may be needed for TOPMed data. \n",
    "\n",
    "# Detailed Example\n",
    "\n",
    "We use the [1000 genomes chromosome 22](http://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/b37.vcf/) as an example. As show below, this data contains 424147 SNPs and 2504 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrecords(data) = 424147\n",
      "nsamples(data) = 2504\n"
     ]
    }
   ],
   "source": [
    "# load necessary packages in Julia\n",
    "using VCFTools\n",
    "\n",
    "# compute simple summary statistics\n",
    "data = \"chr22.1kg.phase3.v5a.vcf.gz\"\n",
    "@show nrecords(data)\n",
    "@show nsamples(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More summary statistics can be computed using the [gtstats](https://openmendel.github.io/VCFTools.jl/dev/man/api/#VCFTools.gtstats) function in `VCFTools.jl`, with example usage [here](https://openmendel.github.io/VCFTools.jl/dev/man/summaryinfo/#Summary-statistics).\n",
    "\n",
    "## Step 1: generating realistic reference and target data \n",
    "\n",
    "First we generate a reference panel and imputation target based on the 1000 genomes data. More specifically, we take the 1000 genomes chromosome 22 and divide it so that \n",
    "+ 100 samples are randomly selected as imputation targets, where\n",
    "    - 100k SNPs with minor allele frequency $\\ge 0.05$ are randomly selected to be the typed positions. \n",
    "    - 0.1% of typed SNPs are masked (mimicking GWAS errors)\n",
    "    - Genotypes are unphased\n",
    "+ The remaining 2404 samples are used as reference haplotypes. \n",
    "+ SNPs with duplicate positions are filtered out.\n",
    "+ All multiallelic markers are filtered out.\n",
    "\n",
    "**Instruction: execute the code below in a Julia session or a Jupyter notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MendelImpute [e47305d1-6a61-5370-bc5d-77554d143183]\n",
      "└ @ Base loading.jl:1278\n",
      "\u001b[32mfinding duplicate markers...100%|███████████████████████| Time: 0:03:56\u001b[39m\n",
      "\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:46\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292.131527 seconds (3.20 G allocations: 301.789 GiB, 7.89% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:02\u001b[39m\n",
      "\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:03:59\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244.425505 seconds (3.18 G allocations: 301.694 GiB, 9.69% gc time)\n",
      "  1.935526 seconds (20.00 M allocations: 1.491 GiB, 6.33% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:10\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.505399 seconds (3.27 G allocations: 317.749 GiB, 9.95% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:07:27\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453.383147 seconds (6.16 G allocations: 566.535 GiB, 10.16% gc time)\n"
     ]
    }
   ],
   "source": [
    "# load necessary packages in Julia\n",
    "using MendelImpute\n",
    "using VCFTools\n",
    "using Random\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2020)\n",
    "\n",
    "# download example data \n",
    "data = \"chr22.1kg.phase3.v5a.vcf.gz\"\n",
    "if !isfile(data) \n",
    "    download(\"http://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/b37.vcf/chr22.1kg.phase3.v5a.vcf.gz\")\n",
    "end\n",
    "\n",
    "# remove SNPs with the same positions, keep all samples, save result into new file\n",
    "SNPs_to_keep = .!find_duplicate_marker(data) \n",
    "@time VCFTools.filter(data, SNPs_to_keep, 1:nsamples(data), des = \"chr22.uniqueSNPs.vcf.gz\")\n",
    "\n",
    "# summarize data\n",
    "total_snps, samples, _, _, _, maf_by_record, _ = gtstats(\"chr22.uniqueSNPs.vcf.gz\")\n",
    "\n",
    "# generate target file with 100 samples and 100k snps with maf>0.05\n",
    "n = 100\n",
    "p = 100000\n",
    "record_idx = falses(total_snps)\n",
    "large_maf = findall(x -> x > 0.05, maf_by_record)  \n",
    "Random.shuffle!(large_maf)\n",
    "record_idx[large_maf[1:p]] .= true\n",
    "sample_idx = falses(samples)\n",
    "sample_idx[1:n] .= true\n",
    "Random.shuffle!(sample_idx)\n",
    "@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", record_idx, sample_idx, \n",
    "    des = \"target.chr22.typedOnly.vcf.gz\", allow_multiallelic=false)\n",
    "\n",
    "# unphase and mask 0.1% entries in target file\n",
    "masks = falses(p, n)\n",
    "missingprop = 0.001\n",
    "for j in 1:n, i in 1:p\n",
    "    rand() < missingprop && (masks[i, j] = true)\n",
    "end\n",
    "@time mask_gt(\"target.chr22.typedOnly.vcf.gz\", masks, \n",
    "    des=\"target.chr22.typedOnly.masked.vcf.gz\", unphase=true)\n",
    "\n",
    "# generate target panel with all snps (this file contains true phase and genotypes)\n",
    "@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, \n",
    "    sample_idx, des = \"target.chr22.full.vcf.gz\", allow_multiallelic=false)\n",
    "\n",
    "# generate reference panel with 2404 samples\n",
    "@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, .!sample_idx, \n",
    "    des = \"ref.chr22.excludeTarget.vcf.gz\", allow_multiallelic=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output explanation:\n",
    "\n",
    "You just generated reference and target VCF files:\n",
    "\n",
    "+ `ref.chr22.excludeTarget.vcf.gz`: Reference haplotype panel with 2404 samples\n",
    "+ `target.chr22.typedOnly.masked.vcf.gz`: Imputation target file containing 100 samples at 100k SNPs. All genotypes are unphased and contains 0.1% missing data. \n",
    "\n",
    "You also generated/downloaded:\n",
    "\n",
    "+ `chr22.1kg.phase3.v5a.vcf.gz`: The original chromosome 22 data downloaded from Beagle's website.\n",
    "+ `chr22.uniqueSNPs.vcf.gz`: This is the original chromosome 22 data excluding duplicate records (SNPs) by checking marker positions. The first SNP is included but all subsequent SNPs are removed. \n",
    "+ `target.chr22.full.vcf.gz`: The complete data for imputation target, used for checking imputation accuracy. All genotypes are phased and non-missing. \n",
    "+ `target.chr22.typedOnly.vcf.gz`: Complete target data on just the typed SNPs. All genotypes are phased and non-missing. Just by-producted for generating other files; not used for anything downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: generating `.jlso` compressed reference panel\n",
    "\n",
    "MendelImpute requires one to pre-process the reference panel for faster reading. This is achieved via the [compress_haplotypes](https://openmendel.github.io/MendelImpute.jl/dev/man/api/#MendelImpute.compress_haplotypes) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:02:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.546081 seconds (2.09 G allocations: 209.215 GiB, 10.53% gc time)\n"
     ]
    }
   ],
   "source": [
    "# load necessary packages in Julia\n",
    "using MendelImpute\n",
    "\n",
    "max_d = 1000 # maximum number of unique haplotypes per window\n",
    "reffile = \"ref.chr22.excludeTarget.vcf.gz\"\n",
    "tgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\n",
    "outfile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\n",
    "@time compress_haplotypes(reffile, tgtfile, outfile, max_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run imputation and phasing\n",
    "\n",
    "Below runs the main [phase](https://openmendel.github.io/MendelImpute.jl/dev/man/api/#MendelImpute.phase) function in a single thread. By default all output genotypes will be phased and non-missing. A list of optional inputs can be found in the [API](https://openmendel.github.io/MendelImpute.jl/dev/man/api/#MendelImpute.phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of threads = 1\n",
      "Importing reference haplotype data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:22\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows = 1634, averaging ~ 508 unique haplotypes per window.\n",
      "\n",
      "Timings: \n",
      "    Data import                     = 11.7924 seconds\n",
      "        import target data             = 2.19475 seconds\n",
      "        import compressed haplotypes   = 9.59764 seconds\n",
      "    Computing haplotype pair        = 22.7438 seconds\n",
      "        BLAS3 mul! to get M and N      = 1.02485 seconds per thread\n",
      "        haplopair search               = 17.9195 seconds per thread\n",
      "        initializing missing           = 0.10093 seconds per thread\n",
      "        allocating and viewing         = 0.23331 seconds per thread\n",
      "        index conversion               = 0.0167426 seconds per thread\n",
      "    Phasing by win-win intersection = 4.82003 seconds\n",
      "        Window-by-window intersection  = 0.470939 seconds per thread\n",
      "        Breakpoint search              = 3.18628 seconds per thread\n",
      "        Recording result               = 0.191996 seconds per thread\n",
      "    Imputation                     = 3.53341 seconds\n",
      "        Imputing missing               = 0.153846 seconds\n",
      "        Writing to file                = 3.37957 seconds\n",
      "\n",
      "    Total time                      = 43.0812 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# note: run twice for more accurate timing\n",
    "reffile = \"ref.chr22.maxd1000.excludeTarget.jlso\" # jlso reference file\n",
    "tgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"  # target genotype file\n",
    "outfile = \"mendel.imputed.chr22.vcf.gz\"           # output file name\n",
    "phase(tgtfile, reffile; outfile=outfile);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs after the first `;` are all optional. The second `;` hides the output, or else the screen will be too jammed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note\n",
    "\n",
    "    To run MendelImpute in parallel, type `export JULIA_NUM_THREADS=4` **before** starting Julia. See Performance Gotchas #1 on the left for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.5: (only for simulated data) check imputation accuracy\n",
    "\n",
    "Since we simulated data, we can check imputation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error overall = 0.00527504782243333\n"
     ]
    }
   ],
   "source": [
    "X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\")    # import true genotypes\n",
    "X_mendel = convert_gt(Float64, \"mendel.imputed.chr22.vcf.gz\") # import imputed genotypes\n",
    "n, p = size(X_mendel)\n",
    "println(\"error overall = $(sum(X_mendel .!= X_truth) / n / p)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Post-Imputation Quality Control\n",
    "\n",
    "MendelImpute also computes a rough quality score (file ending in `sample.error`) for measuring how well each sample is imputed. This value is the sum of the least squares error in each window. A value of 0 is best, and high values mean worse. For more detail, please refer to our paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m                  ┌                                        ┐\u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m  0.0\u001b[90m, \u001b[0m100.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇\u001b[39m\u001b[0m 2                                     \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m100.0\u001b[90m, \u001b[0m200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 58 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m200.0\u001b[90m, \u001b[0m300.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 17                          \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m300.0\u001b[90m, \u001b[0m400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇\u001b[39m\u001b[0m 7                                  \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m400.0\u001b[90m, \u001b[0m500.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇\u001b[39m\u001b[0m 9                                \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m500.0\u001b[90m, \u001b[0m600.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 3                                    \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m600.0\u001b[90m, \u001b[0m700.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 3                                    \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m700.0\u001b[90m, \u001b[0m800.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇\u001b[39m\u001b[0m 1                                     \u001b[90m \u001b[39m \n",
       "\u001b[90m                  └                                        ┘\u001b[39m \n",
       "\u001b[0m                                  Frequency"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, UnicodePlots\n",
    "quality = CSV.read(\"mendel.imputed.chr22.sample.error\") # import quality score \n",
    "histogram(quality[:error]) # plot in histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want this histogram to look like this: most samples have small error (well imputed), and only a few have large error (not imputed well, relatively speaking). A histogram with large right tail indicates poor imputation. "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

var documenterSearchIndex = {"docs":
[{"location":"man/Phasing_and_Imputation/#Preparing-Target-Data","page":"Phasing and Imputation","title":"Preparing Target Data","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute accepts VCF and PLINK files (BGEN format is experimental). Please make sure the following are true:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"VCF file ends in .vcf or .vcf.gz (phased or unphased and may contain missing data)\nFor PLINK files, all trios (.bim, .bed, .fam) are present in the same directory\nEach file contains only 1 (non-sex) chromosome\nEvery record (SNP) is present in the reference panel. If this is untrue, you must match markers in 2 VCF files. \nGiven a SNP, its CHROM, POS, REF, and  ALT fields are the same in target data and reference panel. MendelImpute use SNP position internally to align markers. Note this is not explicitly checked. \nThe position of every SNP is unique: so multiallelic markers should be excluded instead of split (this requirement will eventually be lifted). ","category":"page"},{"location":"man/Phasing_and_Imputation/#Preparing-Reference-Haplotype-Panel","page":"Phasing and Imputation","title":"Preparing Reference Haplotype Panel","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Reference samples must be in VCF (.vcf or .vcf.gz) format, be phased, and contain no missing genotypes. Reference VCF panels must be compressed into .jlso format first using the compress_haplotypes function. One must specify d: the maximum number of unique haplotypes per window. Larger d slows down computation, but increases accuracy. For most purposes, we recommend d approx 1000. ","category":"page"},{"location":"man/Phasing_and_Imputation/#Detailed-Example","page":"Phasing and Imputation","title":"Detailed Example","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"We use the 1000 genomes chromosome 22 as an example. As show below, this data contains 424147 SNPs and 2504 samples.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing VCFTools\nusing MendelImpute\nusing VCFTools\nusing Random\n\n# compute simple summary statistics\ndata = \"chr22.1kg.phase3.v5a.vcf.gz\"\n@show nrecords(data)\n@show nsamples(data);","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"┌ Info: Precompiling MendelImpute [e47305d1-6a61-5370-bc5d-77554d143183]\n└ @ Base loading.jl:1317\n\n\nnrecords(data) = 424147\nnsamples(data) = 2504","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"More summary statistics can be computed using the gtstats function in VCFTools.jl, with example usage here.","category":"page"},{"location":"man/Phasing_and_Imputation/#Step-1:-generating-realistic-reference-and-target-data","page":"Phasing and Imputation","title":"Step 1: generating realistic reference and target data","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"First we generate a reference panel and imputation target based on the 1000 genomes data. Specifically, we divide the 1000 genomes chromosome 22 data so that ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"100 samples are randomly selected as imputation targets, where\n100k SNPs with minor allele frequency ge 005 are randomly selected to be the typed positions. \n0.1% of typed SNPs are masked (mimicking genotyping errors)\nGenotypes are unphased\nThe remaining 2404 samples are used as reference haplotypes. \nSNPs with duplicate positions are filtered out.\nAll multiallelic markers are filtered out.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Instruction: execute the code below in a Julia session or a Jupyter notebook:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# set random seed for reproducibility\nRandom.seed!(2020)\n\n# download example data \ndata = \"chr22.1kg.phase3.v5a.vcf.gz\"\nif !isfile(data) \n    download(\"http://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/b37.vcf/chr22.1kg.phase3.v5a.vcf.gz\")\nend\n\n# remove SNPs with the same positions, keep all samples, save result into new file\nSNPs_to_keep = .!find_duplicate_marker(data) \n@time VCFTools.filter(data, SNPs_to_keep, 1:nsamples(data), des = \"chr22.uniqueSNPs.vcf.gz\")\n\n# summarize data\ntotal_snps, samples, _, _, _, maf_by_record, _ = gtstats(\"chr22.uniqueSNPs.vcf.gz\")\n\n# generate target file with 100 samples and 100k snps with maf>0.05\nn = 100\np = 100000\nrecord_idx = falses(total_snps)\nlarge_maf = findall(x -> x > 0.05, maf_by_record)  \nRandom.shuffle!(large_maf)\nrecord_idx[large_maf[1:p]] .= true\nsample_idx = falses(samples)\nsample_idx[1:n] .= true\nRandom.shuffle!(sample_idx)\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", record_idx, sample_idx, \n    des = \"target.chr22.typedOnly.vcf.gz\", allow_multiallelic=false)\n\n# unphase and mask 0.1% entries in target file\nmasks = falses(p, n)\nmissingprop = 0.001\nfor j in 1:n, i in 1:p\n    rand() < missingprop && (masks[i, j] = true)\nend\n@time mask_gt(\"target.chr22.typedOnly.vcf.gz\", masks, \n    des=\"target.chr22.typedOnly.masked.vcf.gz\", unphase=true)\n\n# generate target panel with all snps (this file contains true phase and genotypes)\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, \n    sample_idx, des = \"target.chr22.full.vcf.gz\", allow_multiallelic=false)\n\n# generate reference panel with 2404 samples\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, .!sample_idx, \n    des = \"ref.chr22.excludeTarget.vcf.gz\", allow_multiallelic=false)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"┌ Info: Precompiling MendelImpute [e47305d1-6a61-5370-bc5d-77554d143183]\n└ @ Base loading.jl:1278\n\u001b[32mfinding duplicate markers...100%|███████████████████████| Time: 0:03:56\u001b[39m\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:46\u001b[39m\n\n\n292.131527 seconds (3.20 G allocations: 301.789 GiB, 7.89% gc time)\n\n\n\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:02\u001b[39m\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:03:59\u001b[39m\n\n\n244.425505 seconds (3.18 G allocations: 301.694 GiB, 9.69% gc time)\n  1.935526 seconds (20.00 M allocations: 1.491 GiB, 6.33% gc time)\n\n\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:10\u001b[39m\n\n\n255.505399 seconds (3.27 G allocations: 317.749 GiB, 9.95% gc time)\n\n\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:07:27\u001b[39m\n\n\n453.383147 seconds (6.16 G allocations: 566.535 GiB, 10.16% gc time)","category":"page"},{"location":"man/Phasing_and_Imputation/#Output-explanation:","page":"Phasing and Imputation","title":"Output explanation:","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"You just generated reference and target VCF files:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"ref.chr22.excludeTarget.vcf.gz: Reference haplotype panel with 2404 samples\ntarget.chr22.typedOnly.masked.vcf.gz: Imputation target file containing 100 samples at 100k SNPs. All genotypes are unphased and contains 0.1% missing data. ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"You also generated/downloaded:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"chr22.1kg.phase3.v5a.vcf.gz: The original chromosome 22 data downloaded from Beagle's website.\nchr22.uniqueSNPs.vcf.gz: This is the original chromosome 22 data excluding duplicate records (SNPs) by checking marker positions. The first SNP is included but all subsequent SNPs are removed. \ntarget.chr22.full.vcf.gz: The complete data for imputation target, used for checking imputation accuracy. All genotypes are phased and non-missing. \ntarget.chr22.typedOnly.vcf.gz: Complete target data on just the typed SNPs. All genotypes are phased and non-missing. Just by-producted for generating other files; not used for anything downstream.","category":"page"},{"location":"man/Phasing_and_Imputation/#Step-2:-generating-.jlso-compressed-reference-panel","page":"Phasing and Imputation","title":"Step 2: generating .jlso compressed reference panel","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute requires one to pre-process the reference panel for faster reading. This is achieved via the compress_haplotypes function.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing MendelImpute\n\nmax_d = 1000 # maximum number of unique haplotypes per window\nreffile = \"ref.chr22.excludeTarget.vcf.gz\"\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\noutfile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\n@time compress_haplotypes(reffile, tgtfile, outfile, max_d)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:02:00\u001b[39m\n\n\n295.546081 seconds (2.09 G allocations: 209.215 GiB, 10.53% gc time)","category":"page"},{"location":"man/Phasing_and_Imputation/#Step-3:-Run-imputation-and-phasing","page":"Phasing and Imputation","title":"Step 3: Run imputation and phasing","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"The phase function will perform imputation and phasing. By default, all output genotypes will be phased and non-missing. A list of optional inputs can be found in the API.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# note: run twice for more accurate timing\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\" # jlso reference file\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"  # target genotype file\noutfile = \"mendel.imputed.chr22.vcf.gz\"           # output file name\nphase(tgtfile, reffile, outfile);","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:25\u001b[39m\n\u001b[32mPhasing...100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 12.6331 seconds\n        import target data             = 3.54785 seconds\n        import compressed haplotypes   = 9.08523 seconds\n    Computing haplotype pair        = 25.8112 seconds\n        BLAS3 mul! to get M and N      = 1.14179 seconds per thread\n        haplopair search               = 19.8237 seconds per thread\n        initializing missing           = 0.11383 seconds per thread\n        allocating and viewing         = 0.183436 seconds per thread\n        index conversion               = 0.0146743 seconds per thread\n    Phasing by win-win intersection = 5.31061 seconds\n        Window-by-window intersection  = 0.56512 seconds per thread\n        Breakpoint search              = 3.4102 seconds per thread\n        Recording result               = 0.182498 seconds per thread\n    Imputation                     = 5.03281 seconds\n        Imputing missing               = 1.15402 seconds\n        Writing to file                = 3.87878 seconds\n\n    Total time                      = 48.9418 seconds","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"The ; hides the output, or else the screen will be too jammed. ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"note: Note\nTo run MendelImpute in parallel, type export JULIA_NUM_THREADS=4 before starting Julia or Jupyter notebooks. See Performance Gotchas #1 on the left for details.","category":"page"},{"location":"man/Phasing_and_Imputation/#Step-3.5:-(only-for-simulated-data)-check-imputation-accuracy","page":"Phasing and Imputation","title":"Step 3.5: (only for simulated data) check imputation accuracy","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Since we simulated data, we can check imputation accuracy.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\")    # import true genotypes\nX_mendel = convert_gt(Float64, \"mendel.imputed.chr22.vcf.gz\") # import imputed genotypes\nn, p = size(X_mendel)\nprintln(\"error overall = \", sum(X_mendel .!= X_truth) / n / p)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"error overall = 0.005273994412137202","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Thus, we are looking at about 5 imputation error out of every 1000 SNPs. ","category":"page"},{"location":"man/Phasing_and_Imputation/#Post-imputation:-per-SNP-Imputation-Quality-Score","page":"Phasing and Imputation","title":"Post-imputation: per-SNP Imputation Quality Score","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Consider the observed genotype x_ij in 0 2 cup missing at SNP i of sample j and the corresponding imputed genotype g_ij derived from the two extended haplotypes of j. If S_i denotes the set of individuals with observed genotypes at the SNP, then MendelImpute's quality score q_i for the SNP is defined as","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"q_i = 1 - frac1S_isum_j in S_i left(fracx_ij - g_ij2right)^2","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Note that 0 le q_i le 1 and that the larger the quality score, the more confidence in the imputed values. Because q_i can only be computed for the typed SNPs, an untyped SNP is assigned the average of the quality scores for its two closest flanking typed SNPs.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"To extract this score from a VCF file, one can do:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"using VariantCallFormat, Plots\nreader = VCF.Reader(openvcf(outfile, \"r\"))\nsnpscores = Vector{Float64}(undef, nrecords(outfile))\n\n# loop over SNPs\nfor (i, record) in enumerate(reader)\n    snpscores[i] = parse(Float64, VCF.info(record)[1].second)\nend\nclose(reader)\n\n# plot histogram of SNP scores\nhistogram(snpscores, label=:none, xlabel=\"per-SNP quality score\", \n    ylabel=\"SNP counts\", bins=30)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"(Image: svg)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Conclusion: Most SNPs are well imputed (quality score close to 10), but a few have subpar quality score (e.g. below 0999). We recommend such SNPs to be filtered out. ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"note: Note\nThe popular correlation metric r^2 such as this one is NOT a good metric for measuring imputation accuracy under MendelImpute's model, because all imputed SNPs will have r^2 = 1. For details, please see our paper. ","category":"page"},{"location":"man/Phasing_and_Imputation/#Post-imputation:-per-sample-Imputation-Quality-score","page":"Phasing and Imputation","title":"Post-imputation: per-sample Imputation Quality score","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute also computes a rough quality score (file ending in sample.error) for measuring how well each sample is imputed. This value is the sum of the least squares error for all typed SNPs scaled by the total number of observed SNPs, similar to the per-SNP quality score. A value of 1.0 is best, and 0 is worst. ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"using CSV, DataFrames\nquality = CSV.read(\"mendel.imputed.chr22.sample.error\", DataFrame) # import quality score \n\n# visualize error distribution\nhistogram(quality[:error], label=:none, xlabel=\"per-sample quality score\",\n    ylabel=\"Number of samples\") ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"(Image: svg)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Conclusion: Most samples are well imputed (e.g. score close to 1), but some samples are indeed poorly imputed. From the histogram, we can safely filtered out samples with score  0999 as that would remove poorly imputed individuals without reducing sample size too much.","category":"page"},{"location":"man/script/#Run-MendelImpute-as-script","page":"Run as script","title":"Run MendelImpute as script","text":"","category":"section"},{"location":"man/script/","page":"Run as script","title":"Run as script","text":"If you don't want to run MendelImpute.jl in a Julia session (e.g. you want to run batch jobs on a cluster), you can do so by putting the code below in a Julia file. For example, in order to run with 8 threads, create a file called impute.jl which contains:","category":"page"},{"location":"man/script/","page":"Run as script","title":"Run as script","text":"# place these code in a file called impute.jl\nusing MendelImpute, VCFTools, LinearAlgebra\n\n# setup code goes here\nreffile = ARGS[1]       # first command line argument\ntgtfile = ARGS[2]       # second command line argument\noutfile = ARGS[3]       # third command line argument\nBLAS.set_num_threads(1) # set BLAS threads to 1 (see performance gotchas)\n\n# run MendelImpute with default options\nphase(tgtfile, reffile, outfile)","category":"page"},{"location":"man/script/","page":"Run as script","title":"Run as script","text":"Then in the terminal/command-prompt, you can do","category":"page"},{"location":"man/script/","page":"Run as script","title":"Run as script","text":"export JULIA_NUM_THREADS=8\njulia impute.jl ref.jlso target.vcf.gz output.vcf.gz","category":"page"},{"location":"man/painting/#Estimating-ancestry","page":"Estimating ancestry","title":"Estimating ancestry","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"If samples in the reference haplotype panel are labeled with a population origin, MendelImpute can also be used for:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Estimate admixed proportions\nChromosome painting","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# first load all necessary packages\nusing MendelImpute\nusing VCFTools\nusing GeneticVariation\nusing Random\nusing DataFrames\nusing Plots\nusing JLSO\nusing CSV","category":"page"},{"location":"man/painting/#Data-preparation","page":"Estimating ancestry","title":"Data preparation","text":"","category":"section"},{"location":"man/painting/#Step-1.-Filter-chromosome-data","page":"Estimating ancestry","title":"Step 1. Filter chromosome data","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We use the 1000 genomes chromosome 22 as illustration.  The original data is filtered into target and reference panels. Follow detailed example in Phasing and Imputation to obtain the same data.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"note: Note\nIn practice, it is better to infer ancestry of admixed populations using non-admixed reference populations. The example here is a simplified illustration and should not be taken too literally. ","category":"page"},{"location":"man/painting/#Step-2.-Process-each-sample's-population-origin","page":"Estimating ancestry","title":"Step 2. Process each sample's population origin","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"MendelImpute needs to know each reference sample's origin (country/ethnicity/region...etc). This origin information should be provided by the reference haplotype panel, but users are free to further organize origin labels base on their own criteria. As in our paper, we use super-populations. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"To do so, we need to create a Dict{key, value} where each key is a sample ID and the value is the population code. This will be used for both the paint and composition function.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# map population to super-population\npop_to_superpop = Dict{String, String}()\n\n# 5 east asian\npop_to_superpop[\"CHB\"] = \"EAS\"; pop_to_superpop[\"JPT\"] = \"EAS\"; pop_to_superpop[\"CHS\"] = \"EAS\"; \npop_to_superpop[\"CDX\"] = \"EAS\"; pop_to_superpop[\"KHV\"] = \"EAS\"; \n\n# 5 european\npop_to_superpop[\"CEU\"] = \"EUR\"; pop_to_superpop[\"TSI\"] = \"EUR\"; pop_to_superpop[\"FIN\"] = \"EUR\";\npop_to_superpop[\"GBR\"] = \"EUR\"; pop_to_superpop[\"IBS\"] = \"EUR\";\n\n# 7 african\npop_to_superpop[\"YRI\"] = \"AFR\"; pop_to_superpop[\"LWK\"] = \"AFR\"; pop_to_superpop[\"GWD\"] = \"AFR\"; \npop_to_superpop[\"MSL\"] = \"AFR\"; pop_to_superpop[\"ESN\"] = \"AFR\"; pop_to_superpop[\"ASW\"] = \"AFR\"; \npop_to_superpop[\"ACB\"] = \"AFR\"; \n\n# 4 ad mixed americans\npop_to_superpop[\"MXL\"] = \"AMR\"; pop_to_superpop[\"PUR\"] = \"AMR\"; pop_to_superpop[\"CLM\"] = \"AMR\"; \npop_to_superpop[\"PEL\"] = \"AMR\";\n\n# 5 south asian\npop_to_superpop[\"GIH\"] = \"SAS\"; pop_to_superpop[\"PJL\"] = \"SAS\"; pop_to_superpop[\"BEB\"] = \"SAS\"; \npop_to_superpop[\"STU\"] = \"SAS\"; pop_to_superpop[\"ITU\"] = \"SAS\";","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# read population origin into a dataframe\nfile = joinpath(normpath(MendelImpute.datadir()), \"1000genomes.population.txt\")\ndf = CSV.read(file, DataFrame)\n\n# create dictionary with key = ID, value = population \nrefID_to_population = Dict{String, String}()\nrefID_to_superpopulation = Dict{String, String}()\nfor (id, population) in eachrow(df)\n     refID_to_population[id] = population\n     refID_to_superpopulation[id] = pop_to_superpop[population]\nend\nrefID_to_superpopulation","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Dict{String,String} with 2504 entries:\n  \"HG01791\" => \"EUR\"\n  \"HG02736\" => \"SAS\"\n  \"HG00182\" => \"EUR\"\n  \"HG03914\" => \"SAS\"\n  \"HG00149\" => \"EUR\"\n  \"NA12156\" => \"EUR\"\n  \"HG02642\" => \"AFR\"\n  \"HG02851\" => \"AFR\"\n  \"NA19835\" => \"AFR\"\n  \"NA19019\" => \"AFR\"\n  \"HG01131\" => \"AMR\"\n  \"HG03578\" => \"AFR\"\n  \"NA18550\" => \"EAS\"\n  \"HG02401\" => \"EAS\"\n  \"HG01350\" => \"AMR\"\n  \"HG03973\" => \"SAS\"\n  \"NA07000\" => \"EUR\"\n  \"HG01709\" => \"EUR\"\n  \"HG01395\" => \"AMR\"\n  \"HG01980\" => \"AMR\"\n  \"HG01979\" => \"AMR\"\n  \"HG01122\" => \"AMR\"\n  \"HG03869\" => \"SAS\"\n  \"HG03729\" => \"SAS\"\n  \"NA19920\" => \"AFR\"\n  ⋮         => ⋮","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note the population codes for 1000 genome's samples are explained here. ","category":"page"},{"location":"man/painting/#Step-3.-Compute-phase-information-using-MendelImpute","page":"Estimating ancestry","title":"Step 3. Compute phase information using MendelImpute","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"This is equivalent to running a typical imputation. Please ensure that:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The output file name ends with .jlso (save output to ultra-compressed format)\nimpute = true (so the output contains the entire chromosome)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note data used here is prepared in Detailed Example.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# compute each person's phase information\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\noutfile = \"mendel.imputed.jlso\"\n@time ph = phase(tgtfile, reffile, outfile);","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:28\u001b[39m\n\u001b[32mPhasing...100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 13.8493 seconds\n        import target data             = 3.61007 seconds\n        import compressed haplotypes   = 10.2393 seconds\n    Computing haplotype pair        = 28.5288 seconds\n        BLAS3 mul! to get M and N      = 1.20264 seconds per thread\n        haplopair search               = 22.9585 seconds per thread\n        initializing missing           = 0.121591 seconds per thread\n        allocating and viewing         = 0.337528 seconds per thread\n        index conversion               = 0.014748 seconds per thread\n    Phasing by win-win intersection = 5.92058 seconds\n        Window-by-window intersection  = 0.581821 seconds per thread\n        Breakpoint search              = 4.05849 seconds per thread\n        Recording result               = 0.146574 seconds per thread\n    Imputation                     = 3.65652 seconds\n        Imputing missing               = 0.0221378 seconds\n        Writing to file                = 3.63439 seconds\n\n    Total time                      = 52.1137 seconds\n\n 58.377736 seconds (96.50 M allocations: 5.471 GiB, 4.24% gc time)","category":"page"},{"location":"man/painting/#Estimate-admixture-proportions","page":"Estimating ancestry","title":"Estimate admixture proportions","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The composition will compute a list of percentages where composition[i] equals the sample's ancestry (in %) from populations[i].\nThis illustration depends on data preparation above. ","category":"page"},{"location":"man/painting/#Step-1:-import-necessary-data","page":"Estimating ancestry","title":"Step 1: import necessary data","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# First import compressed reference panel\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\ncompressed_Hunique = MendelImpute.read_jlso(reffile)\npanelID = compressed_Hunique.sampleID\n\n# also need target sample's ancestry\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreader = VCF.Reader(openvcf(tgtfile, \"r\"))\ntgtID  = VCF.header(reader).sampleID\nsample_population = [refID_to_population[id] for id in tgtID]\nsample_superpopulation = [refID_to_superpopulation[id] for id in tgtID];","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# here is each sample's super-population (sample 1 is EUR, sample 3 is EAS...etc)\nsample_superpopulation","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"100-element Array{String,1}:\n \"EUR\"\n \"EUR\"\n \"EAS\"\n \"EAS\"\n \"EAS\"\n \"EAS\"\n \"AMR\"\n \"AMR\"\n \"AMR\"\n \"AMR\"\n \"EUR\"\n \"AMR\"\n \"EUR\"\n ⋮\n \"AMR\"\n \"AFR\"\n \"AFR\"\n \"EUR\"\n \"EUR\"\n \"EUR\"\n \"EUR\"\n \"EUR\"\n \"EUR\"\n \"EUR\"\n \"SAS\"\n \"SAS\"","category":"page"},{"location":"man/painting/#Step-2:-call-composition-function","page":"Estimating ancestry","title":"Step 2: call composition function","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The composition will compute a list of percentages where composition[i] equals the sample's ancestry (in %) from populations[i].\nWe are finally using the imputation result stored in ph.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"populations = MendelImpute.unique_populations(refID_to_superpopulation)\n@time sample1_comp = composition(ph[1], panelID, refID_to_superpopulation) # origin GBR (EUR)\n@time sample4_comp = composition(ph[4], panelID, refID_to_superpopulation) # origin CHS (EAS)\n@time sample84_comp = composition(ph[84], panelID, refID_to_superpopulation) # origin LWK (AFR)\n\nprintln(\"sample 1 = \", round(sample1_comp[1], digits=3), \" S. asian\")\nprintln(\"sample 1 = \", round(sample1_comp[2], digits=3), \" E. asian\")\nprintln(\"sample 1 = \", round(sample1_comp[3], digits=3), \" European\")\nprintln(\"sample 1 = \", round(sample1_comp[4], digits=3), \" Admixed-American\")\nprintln(\"sample 1 = \", round(sample1_comp[5], digits=3), \" Africans\\n\")\n\nprintln(\"sample 4 = \", round(sample4_comp[1], digits=3), \" S. asian\")\nprintln(\"sample 4 = \", round(sample4_comp[2], digits=3), \" E. asian\")\nprintln(\"sample 4 = \", round(sample4_comp[3], digits=3), \" European\")\nprintln(\"sample 4 = \", round(sample4_comp[4], digits=3), \" Admixed-American\")\nprintln(\"sample 4 = \", round(sample4_comp[5], digits=3), \" Africans\\n\")\n    \nprintln(\"sample 84 = \", round(sample84_comp[1], digits=3), \" S. asian\")\nprintln(\"sample 84 = \", round(sample84_comp[2], digits=3), \" E. asian\")\nprintln(\"sample 84 = \", round(sample84_comp[3], digits=3), \" European\")\nprintln(\"sample 84 = \", round(sample84_comp[4], digits=3), \" Admixed-American\")\nprintln(\"sample 84 = \", round(sample84_comp[5], digits=3), \" Africans\");","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"  0.003909 seconds (26 allocations: 2.000 KiB)\n  0.000167 seconds (6 allocations: 544 bytes)\n  0.000185 seconds (6 allocations: 544 bytes)\nsample 1 = 0.652 S. asian\nsample 1 = 0.088 E. asian\nsample 1 = 0.023 European\nsample 1 = 0.17 Admixed-American\nsample 1 = 0.067 Africans\n\nsample 4 = 0.189 S. asian\nsample 4 = 0.061 E. asian\nsample 4 = 0.01 European\nsample 4 = 0.053 Admixed-American\nsample 4 = 0.687 Africans\n\nsample 84 = 0.065 S. asian\nsample 84 = 0.014 E. asian\nsample 84 = 0.784 European\nsample 84 = 0.111 Admixed-American\nsample 84 = 0.025 Africans","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Here sample1_comp[i] equals the sample's estimated ancestry (in %) from populations[i]. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Conclusion: We computed the population percentages for sample 1, 4, and 84 with respect to the 5 reference super populations. Thus sample 1 is 65% European, 10% South Asian, 20% American...etc. Sample 4 is 20% European, 70% East Asian,...etc. Sample 84 is 80% African and 5% European...etc. ","category":"page"},{"location":"man/painting/#Chromosome-painting","page":"Estimating ancestry","title":"Chromosome painting","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The main function is the paint function. For an imputed sample, it will convert each haplotype segment into a percentage indicating the segment's length in the chromosome. Then the list can be used for easy plotting. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note: this illustration depends on data preparation above. ","category":"page"},{"location":"man/painting/#Step-1:-Choose-your-colors","page":"Estimating ancestry","title":"Step 1: Choose your colors","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"In this example, colors are arranged such that:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Blue ≈ European/American\nRed ≈ South/East Asian\nGreen ≈ African","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Of course, Julia lets you plot your favoriate colors. We pick our colors here: https://mdigi.tools/color-shades/#008000.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"continent = [\"SAS\", \"EAS\", \"EUR\", \"AMR\", \"AFR\"]\ncontinent_colors = [colorant\"#e6194B\", colorant\"#800000\", colorant\"#4363d8\", colorant\"#0000b3\", colorant\"#bfef45\"]","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/#Step-2:-Run-paint-funcion","page":"Estimating ancestry","title":"Step 2: Run paint funcion","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"This function convert the imputed haplotype segments into a list of percentages (one list for each strand). This is simply a post-processing routine so that data can be used for easy plotting later.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"populations = unique_populations(refID_to_superpopulation)\n@time sample1_s1_comp, sample1_s2_comp = paint(ph[1], panelID, refID_to_superpopulation, populations=populations)\n@time sample4_s1_comp, sample4_s2_comp = paint(ph[4], panelID, refID_to_superpopulation, populations=populations)\n@time sample84_s1_comp, sample84_s2_comp = paint(ph[84], panelID, refID_to_superpopulation, populations=populations);","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"  0.072840 seconds (122.95 k allocations: 6.250 MiB)\n  0.000099 seconds (12 allocations: 19.906 KiB)\n  0.000104 seconds (12 allocations: 22.406 KiB)","category":"page"},{"location":"man/painting/#Step-3:-Generate-plots-for-painted-chromosomes","page":"Estimating ancestry","title":"Step 3: Generate plots for painted chromosomes","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We found the StatsPlots.jl package to be more useful for this purpose, although the code below still did the plotting in a very roundabout way. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"using StatsPlots, FixedPointNumbers\n\n# assign a color to each haplotype segment\nsample1_s1_colors = [continent_colors[findfirst(x -> x == pop, continent)] for pop in sample1_s1_comp[2]]\nsample1_s1_colors = reshape(sample1_s1_colors, 1, length(sample1_s1_colors))\nsample1_s2_colors = [continent_colors[findfirst(x -> x == pop, continent)] for pop in sample1_s2_comp[2]]\nsample1_s2_colors = reshape(sample1_s2_colors, 1, length(sample1_s2_colors))\nsample4_s1_colors = [continent_colors[findfirst(x -> x == pop, continent)] for pop in sample4_s1_comp[2]]\nsample4_s1_colors = reshape(sample4_s1_colors, 1, length(sample4_s1_colors))\nsample4_s2_colors = [continent_colors[findfirst(x -> x == pop, continent)] for pop in sample4_s2_comp[2]]\nsample4_s2_colors = reshape(sample4_s2_colors, 1, length(sample4_s2_colors))\nsample84_s1_colors = [continent_colors[findfirst(x -> x == pop, continent)] for pop in sample84_s1_comp[2]]\nsample84_s1_colors = reshape(sample84_s1_colors, 1, length(sample84_s1_colors))\nsample84_s2_colors = [continent_colors[findfirst(x -> x == pop, continent)] for pop in sample84_s2_comp[2]]\nsample84_s2_colors = reshape(sample84_s2_colors, 1, length(sample84_s2_colors));\n\n# roundabout code for plotting...\nsample1_s1l = length(sample1_s1_comp[1])\nsample1_s2l = length(sample1_s2_comp[1])\nsample4_s1l = length(sample4_s1_comp[1])\nsample4_s2l = length(sample4_s2_comp[1])\nsample84_s1l = length(sample84_s1_comp[1])\nsample84_s2l = length(sample84_s2_comp[1])\nmaxlen = max(sample1_s1l, sample1_s2l, sample4_s1l, sample4_s2l, sample84_s1l, sample84_s2l)\n\nmydata = zeros(6, maxlen)\ncopyto!(@view(mydata[1, 1:sample1_s1l]), sample1_s1_comp[1])\ncopyto!(@view(mydata[2, 1:sample1_s2l]), sample1_s2_comp[1])\ncopyto!(@view(mydata[3, 1:sample4_s1l]), sample4_s1_comp[1])\ncopyto!(@view(mydata[4, 1:sample4_s2l]), sample4_s2_comp[1])\ncopyto!(@view(mydata[5, 1:sample84_s1l]), sample84_s1_comp[1])\ncopyto!(@view(mydata[6, 1:sample84_s2l]), sample84_s2_comp[1])\n\npop_colors = Matrix{RGB{Normed{UInt8,8}}}(undef, 6, maxlen)\ncopyto!(@view(pop_colors[1, 1:sample1_s1l]), sample1_s1_colors)\ncopyto!(@view(pop_colors[2, 1:sample1_s2l]), sample1_s2_colors)\ncopyto!(@view(pop_colors[3, 1:sample4_s1l]), sample4_s1_colors)\ncopyto!(@view(pop_colors[4, 1:sample4_s2l]), sample4_s2_colors)\ncopyto!(@view(pop_colors[5, 1:sample84_s1l]), sample84_s1_colors)\ncopyto!(@view(pop_colors[6, 1:sample84_s2l]), sample84_s2_colors)\n\nxnames = [\"Sample 1 hap1\", \"Sample 1 hap2\", \"Sample 4 hap1\", \"Sample 4 hap2\", \"Sample 84 hap1\", \"Sample 84 hap2\"]\nynames = [\"SNP 1\", \"SNP 208k\", \"SNP 417k\"]\n\n# color haplotypes\nchrom_plt2 = groupedbar(mydata, bar_position = :stack, bar_width=0.7, label=:none, \n    lw = 0, color=pop_colors, xticks=(1:1:6, xnames), yticks=(0:0.5:1, ynames),\n    ytickfont=font(12), xtickfont=font(12), xrotation=20, right_margin = 35Plots.mm,\n    grid=false)\n\n# create a plot for legend\ncolor_x = ones(5)\ncolor_y = collect(1:1:5)\nadmixture_chrom_plt = scatter!(color_x, color_y, color=reverse(continent_colors), ytick=(1:1:5, reverse(continent)), \n    xrange=(0.9, 1.1), xtick=false, label=:none, markersize=8, ytickfont=font(16),\n    grid=false, framestyle=:grid, mirror=true, tick_direction=:out, markershape=:rect,\n    inset = (1, bbox(-0.05, 0.0, 0.05, 1.0, :bottom, :right)), subplot = 2)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Conclusion: ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We can visualize the linkage patterns for the 3 samples across their 6 haplotypes\nSample 1 is mostly European and admixed American, sample 2 is mainly South/East Asian, and sample 3 is mainly African.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note: this example should not be taken too literally, since we did not exclude admixed samples from the reference panel. For more details, please refer to our paper, or file an issue on GitHub. ","category":"page"},{"location":"man/ultra+compress/#Ultra-compressed-format","page":"Ultra compression","title":"Ultra-compressed format","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"One can optionally save/load ultra-compressed phased genotypes after imputation. Ultra-compression is nothing fancy. Instead of converting haplotype segments into genotypes, this protocol simply saves the starting position and the correct haplotype label. We put this result into our own data structure, and saving/loading is achieved by the JLSO package. ","category":"page"},{"location":"man/ultra+compress/#Saving","page":"Ultra compression","title":"Saving","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Appending .jlso to the output file name will signal MendelImpute to save data in ultra-compressed format. For admixture estimation, we require one to save in .jlso format.","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"# first load all necessary packages\nusing MendelImpute\nusing VCFTools\n\n# compute each person's phase information\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\noutfile = \"mendel.imputed.jlso\" # output file name ends in jlso!\n@time phaseinfo = phase(tgtfile, reffile, outfile);","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:23\u001b[39m\n\u001b[32mPhasing...100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 13.5855 seconds\n        import target data             = 2.99557 seconds\n        import compressed haplotypes   = 10.5899 seconds\n    Computing haplotype pair        = 23.5138 seconds\n        BLAS3 mul! to get M and N      = 1.02228 seconds per thread\n        haplopair search               = 18.3673 seconds per thread\n        initializing missing           = 0.101495 seconds per thread\n        allocating and viewing         = 0.270367 seconds per thread\n        index conversion               = 0.0212053 seconds per thread\n    Phasing by win-win intersection = 5.17088 seconds\n        Window-by-window intersection  = 0.499549 seconds per thread\n        Breakpoint search              = 3.71212 seconds per thread\n        Recording result               = 0.00855205 seconds per thread\n    Imputation                     = 3.04347 seconds\n        Imputing missing               = 0.0513904 seconds\n        Writing to file                = 2.99208 seconds\n\n    Total time                      = 45.5041 seconds\n\n 60.231372 seconds (124.56 M allocations: 6.857 GiB, 5.31% gc time)","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"The object saved to mendel.imputed.jlso is literally the phaseinfo variable. We can inspect its element:","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"# look at sample 1's haplotype segments\nhaplotype_labels = phaseinfo[1].strand1.haplotypelabel # strand1\nhaplotype_start = phaseinfo[1].strand1.start # strand1\n[haplotype_start haplotype_labels]","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"545×2 Array{Int64,2}:\n      1  4119\n    236   887\n    423   272\n    622    12\n    741   124\n    792     4\n    824    24\n    944  1282\n   1116  1741\n   1202  4543\n   1691  1198\n   3031    22\n   3521    18\n      ⋮  \n 411702   877\n 412185    74\n 413733  3849\n 413868   248\n 414371    31\n 414552  3187\n 414989  4481\n 415807     5\n 415965   143\n 416352  1276\n 416744    71\n 417014   311","category":"page"},{"location":"man/ultra+compress/#Loading","page":"Ultra compression","title":"Loading","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"The function convert_compressed will load the ultra-compressed data into genotype matrices and the original phaseinfo data structure. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Note: Decompressing requires loading the original haplotype reference panel. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"tgtfile = \"mendel.imputed.jlso\" # ultra-compressed genotypes after phasing & imputation\nreffile = \"ref.chr22.excludeTarget.vcf.gz\" # original haplotype reference file\nX1, X2, phaseinfo, sampleID, H = convert_compressed(Float64, tgtfile, reffile);","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:01:51\u001b[39m","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Check this compression protocol exhibit same error rate with standard VCF compression. Note that X1, X2, and H are transposed. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\") # import true genotypes\nX_mendel = (X1 + X2)' # transpose X1 and X2\nn, p = size(X_mendel)\nprintln(\"error overall = $(sum(X_mendel .!= X_truth) / n / p)\")","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"error overall = 0.00527504782243333","category":"page"},{"location":"man/performance/#Performance-gotchas","page":"Performance Gotchas","title":"Performance gotchas","text":"","category":"section"},{"location":"man/performance/#Gotcha-1:-Run-MendelImpute-in-parallel","page":"Performance Gotchas","title":"Gotcha 1: Run MendelImpute in parallel","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"To run MendelImpute.jl in parallel,","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"To use 4 threads, execute export JULIA_NUM_THREADS=4 before starting Julia. \nVerify the Julia session is running in parallel by executing Threads.nthreads() in Julia\nSet the number of BLAS threads to be 1 by using LinearAlgebra; BLAS.set_num_threads(1). This avoids oversubscription. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"note: Note\nWe recommend number of threads equal to the number of physical CPU cores on your machine. Number of Julia threads should never exceed number of physical CPU cores!! Hyperthreading is valuable for I/O operations (in our experience), but not for linear algebra routines used throughout MendelImpute. ","category":"page"},{"location":"man/performance/#Gotcha-2:-Compressing-haplotype-panels-is-slow","page":"Performance Gotchas","title":"Gotcha 2: Compressing haplotype panels is slow","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Currently every new set of typed SNPs requires a new compressed reference haplotype panel. The compression routine is slow because reading raw VCF files is slow. Thus, it is highly advised that one try to use the same set of typed SNPs as much as possible. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"We are actively developing a new set of functions in SnpArrays.jl to alleviate this problem. Since SnpArrays use memory mapping, read times can be improved dramatically. ","category":"page"},{"location":"man/performance/#Gotcha-3:-max_d-too-high-(or-too-low)","page":"Performance Gotchas","title":"Gotcha 3: max_d too high (or too low)","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"When you compress the haplotype panels into a .jlso format, you specified max_d which is the maximum number of unique haplotypes per window. We generally recommend using max_d = 1000, BUT 1000 may be too small if you use a reference panel larger than HRC. In that case, you can try larger max_d, which will improve error rate. ","category":"page"},{"location":"man/performance/#Symptoms-for-max_d-too-high:","page":"Performance Gotchas","title":"Symptoms for max_d too high:","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Computing optimal haplotypes is too slow. In particular, the timing for haplopair search is too high. ","category":"page"},{"location":"man/performance/#Symptoms-for-max_d-too-low:","page":"Performance Gotchas","title":"Symptoms for max_d too low:","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Too few typed SNPs per window indicates max_d is set too low. You can calculate the number of typed SNPs per window by dividing the total number of SNPs in the target file by the total windows (a number that will be output after every run). Ideally you want an average of 400 typed SNPs per window, but something as low as 50 still works. Something like 10~20 is too low. ","category":"page"},{"location":"man/performance/#I-really-want-to-use-a-high-max_d","page":"Performance Gotchas","title":"I really want to use a high max_d","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"A high max_d generally improve error, so it is understandable you want to do so. If a high max_d value runs too slow, try setting stepwise = 100 and max_haplotypes to a number that is close to 1000. This avoids searching the global minimizer of the least-squares problem for windows that have more than max_haplotypes number of unique haplotypes. Setting thinning_factor instead of stepwise have a similar effect. Details for these 2 heuristic searches are explained in the appendix of our paper. ","category":"page"},{"location":"man/performance/#Gotcha-4:-Do-you-have-enough-memory-(RAM)?","page":"Performance Gotchas","title":"Gotcha 4: Do you have enough memory (RAM)?","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"While MendelImpute uses the least RAM compared to competing softwares (as of 2020), it is still possible for large imputation problems to consume all available RAM. If this happens, Julia will first try to use swap before crashing (until all of swap is consumed). Monitor your RAM usage constantly to make sure this doesn't happen. On Mac/Linux machines, the top or htop command will monitor this information. Alternatively, the /usr/bin/time command will automatically records max RAM usage for job and whether any swap had been performed. ","category":"page"},{"location":"man/performance/#Rough-estimate-for-amount-of-RAM-needed","page":"Performance Gotchas","title":"Rough estimate for amount of RAM needed","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"There are 4 things that require lots of memory:","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"The target genotype matrix mathbfX_n times p requires n times p times 8 bits. If mathbfX is dosage data, then you need instead n times p times 32 bits\nThe matrix mathbfM_d times d requires c times d times d times 32 bits, where c is the number of parallel threads used and d is the number specified in the compress_haplotypes function.\nThe matrix mathbfN_n times d requires c times n times d times 32 bits, where c is the number of parallel threads used and d is the number specified in the compress_haplotypes function.\nThe compressed reference haplotype panel produced by the compress_haplotypes function. This typically requires about 3r gigabytes of RAM where r is your panel's size in .vcf.gz. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"If you do not have the above issues and your code is still running slow, file an issue on GitHub and we will take a look at it ASAP. ","category":"page"},{"location":"#MendelImpute.jl","page":"Home","title":"MendelImpute.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Fast genotype imputation, phasing, and admixture estimation!","category":"page"},{"location":"","page":"Home","title":"Home","text":"MendelImpute.jl is the fastest and most memory-efficient software for phasing and genotype imputation, as of 2021. It is also capable of estimating local and global admixture coefficients using a reference haplotype panel.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given a target genotype file (phased or unphased and may contain missing data) and a reference haplotype file (phased, no missing), our software imputes every SNP in the reference file to the target file, outputing phased or unphased genotypes. Like many other software, SNPs typed in target must all be present in the reference panel. ","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Phasing and imputation with respect to a reference haplotype panel\nImputation on dosage data, phasing without imputation, imputation without phasing\nBuilt-in support for VCF (.vcf, .vcf.gz), PLINK, and BGEN  (.bgen, currently experimental) files\nOut-of-the-box multithreaded (shared memory) parallelism. \nAdmixture estimation, with code examples to make pretty plots!\nUltra-compressed file for phased genotypes.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Download and install Julia. Within Julia, copy and paste the following: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\npkg\"add https://github.com/OpenMendel/SnpArrays.jl\"\npkg\"add https://github.com/OpenMendel/VCFTools.jl\"\npkg\"add https://github.com/OpenMendel/BGEN.jl\"\npkg\"add https://github.com/OpenMendel/MendelImpute.jl\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package supports Julia v1.5+.","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"man/Phasing_and_Imputation.md\"\n    \"man/performance.md\"\n    \"man/painting.md\"\n    \"man/ultra+compress.md\"\n    \"man/script.md\"\n    \"man/api.md\"\n]\nDepth = 2","category":"page"},{"location":"man/api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Documentation for MendelImpute.jl's functions.","category":"page"},{"location":"man/api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"man/api/#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"phase\ncompress_haplotypes\npaint\ncomposition\nunique_populations\nconvert_compressed","category":"page"},{"location":"man/api/#MendelImpute.phase","page":"API","title":"MendelImpute.phase","text":"phase(tgtfile::String, reffile::String, outfile::String; [impute::Bool],\n    [phase::Bool], [dosage::Bool], [rescreen::Bool], [max_haplotypes::Int], \n    [stepwise::Int], [thinning_factor::Int], [scale_allelefreq::Bool], \n    [dynamic_programming::Bool])\n\nMain function of MendelImpute program. Phasing (haplotying) of tgtfile from a pool of haplotypes reffile by sliding windows and saves result in outfile. All SNPs in tgtfile must be present in reffile. Per-SNP quality score will be saved in outfile, while per-sample imputation score will be saved in a file ending in sample.error.\n\nInput\n\ntgtfile: VCF or PLINK files. VCF files should end in .vcf or .vcf.gz.   PLINK files should exclude .bim/.bed/.fam trailings but the trio must all   be present in the same directory.\nreffile: Reference haplotype file ending in .jlso (compressed binary files).\noutfile: output filename ending in .vcf.gz, .vcf, or .jlso. VCF output   genotypes will have no missing data. If ending in .jlso, will output   ultra-compressed data structure recording HaplotypeMosaicPairs for    each sample.\n\nOptional Inputs\n\nimpute: If true, imputes every SNPs in reffile to tgtfile. Otherwise   only missing snps in tgtfile will be imputed.\nphase: If true, all output genotypes will be phased, but observed data    (minor allele count) may be changed. If phase=false all output genotypes   will be unphased but observed minor allele count will not change.\ndosage: If true, will assume target matrix are dosages for imputation. Note   this means the genotype matrix will be entirely single precision. \nrescreen: This option is more computationally intensive but gives more   accurate results. It saves a number of top haplotype pairs when solving   the least squares objective, and re-minimize least squares on just   observed data.\nmax_haplotypes: Maximum number of haplotypes for using global search. Windows   exceeding this number of unique haplotypes will be searched using a   heuristic. A non-zero stepscreen or thinning_factor need to be specified \nstepwise: If an integer is specified, will solve the least squares objective   by first finding stepwise top haplotypes using a stepwise heuristic then   finds the next haplotype using global search. Uses max_haplotypes. \nthinning_factor: If an integer is specified, will solve the least squares   objective on only thining_factor unique haplotypes. Uses max_haplotypes.\nscale_allelefreq: Boolean indicating whether to give rare SNPs more weight   scaled by wᵢ = 1 / √2p(1-p) where max weight is 2. \ndynamic_programming: Boolean indicating whether to phase with a global    search that finds the longest haplotype stretch over all windows. (Currently   broken, sorry!)\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.compress_haplotypes","page":"API","title":"MendelImpute.compress_haplotypes","text":"compress_haplotypes(reffile::String, tgtfile::String, outfile::String, \n    [d::Int], [minwidth::Int], [overlap::Float64])\n\nCuts a haplotype matrix reffile into windows of variable width so that each window has less than d unique haplotypes. Saves result to outfile as a compressed binary format. All SNPs in tgtfile must be present in reffile. \n\nWhy is tgtfile required?\n\nThe unique haplotypes in each window is computed on the typed SNPs only.  A genotype matrix tgtfile is used to identify the typed SNPs. In the future,  hopefully we can pre-compute compressed haplotype panels for all genotyping  platforms and provide them as downloadable files. But currently, users must run this function by themselves. \n\nInputs\n\nreffile: reference haplotype file name (ends in .vcf or .vcf.gz)\ntgtfile: VCF or PLINK files. VCF files should end in .vcf or .vcf.gz.   PLINK files should exclude .bim/.bed/.fam suffixes but the trio must all   be present in the same directory.\noutfile: Output file name (ends in .jlso)\n\nOptional Inputs\n\nd: Max number of unique haplotypes per genotype window (default d = 1000). \nminwidth: Minimum number of typed SNPs per window (default 0)\noverlap: How much overlap between adjacent genotype windows in percentage of   each window's width (default 0.0)\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.paint","page":"API","title":"MendelImpute.paint","text":"paint(sample_phase::HaplotypeMosaicPair, panelID::Vector{String},\n    refID_to_population::Dict{String, String}, populations::Vector{String})\n\nConverts a person's phased haplotype lengths into segments of percentages. This function is used for easier plotting a \"painted chromosome\".\n\nInputs\n\nsample_phase: A HaplotypeMosaicPair storing phase information for a   sample, includes haplotype start position and haplotype label.\npanelID: Sample ID's in the reference haplotype panel\nrefID_to_population: A dictionary mapping each ID in the haplotype    reference panel to its population origin. \n\nOptional inputs\n\npopulations: A unique list of populations present in refID_to_population\n\nOutput\n\ncomposition: A list of percentages where composition[i] equals the   sample's ancestry (in %) from populations[i] \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.composition","page":"API","title":"MendelImpute.composition","text":"composition(sample_phase::HaplotypeMosaicPair, panelID::Vector{String}, \n    refID_to_population::Dict{String, String}, [populations::Vector{String}])\n\nComputes a sample's chromosome composition based on phase information. This function is used for easier plotting a person's admixed proportions.\n\nInputs\n\nsample_phase: A HaplotypeMosaicPair storing phase information for a   sample, includes haplotype start position and haplotype label.\npanelID: Sample ID's in the reference haplotype panel\nrefID_to_population: A dictionary mapping each ID in the haplotype    reference panel to its population origin. \n\nOptional inputs\n\npopulations: A unique list of populations present in refID_to_population\n\nOutput\n\ncomposition: A list of percentages where composition[i] equals the   sample's ancestry (in %) from populations[i] \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.unique_populations","page":"API","title":"MendelImpute.unique_populations","text":"unique_populations(x::Dict{String, String})\n\nComputes the unique list of populations, preserving order. x is a Dict where each sample is a key and populations are values. \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.convert_compressed","page":"API","title":"MendelImpute.convert_compressed","text":"convert_compressed(t<:Real, phaseinfo::String, reffile::String)\n\nConverts phaseinfo into a phased genotype matrix of type t using the full reference haplotype panel H \n\nInputs\n\nt: Type of matrix. If bool, genotypes are converted to a BitMatrix\nphaseinfo: Vector of HaplotypeMosaicPairs stored in .jlso format\nreffile: The complete (uncompressed) haplotype reference file\n\nOutput\n\nX1: allele 1 of the phased genotype. Each column is a sample. X = X1 + X2. \nX2: allele 2 of the phased genotype. Each column is a sample. X = X1 + X2. \nphase: the original data structure after phasing and imputation.\nsampleID: The ID's of each imputed person.  \nH: the complete reference haplotype panel. Columns of H are haplotypes.\n\n\n\n\n\nconvert_compressed(t<:Real, phaseinfo::Vector{HaplotypeMosaicPair}, H::AbstractMatrix)\n\nColumns of H are haplotypes.\n\n\n\n\n\n","category":"function"}]
}
